{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_station_profile = pd.read_csv(\"../data/rd_station_profile\")\n",
    "info_student_unimestre = pd.read_csv(\"../data/info_student_unimestre.csv\")\n",
    "first_cd_turma_student = pd.read_csv(\"../data/first_cd_turma_for_student_unimestre.csv\")\n",
    "dt_cadastro_student = pd.read_csv(\"../data/dt_cadastro_student_unimestre.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to get less null values on the min_dt_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_student_unimestre.loc[:, 'min_dt_log'] = (\n",
    "    info_student_unimestre['min_dt_log']\n",
    "    .fillna(first_cd_turma_student['min_date'])\n",
    "    .fillna(dt_cadastro_student['dt_cadastro'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this I was able to reduce \n",
    "- *min_dt_log* had 9163 null values now 209"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a df to be only one row per ds_email (to avoid the duplicates values checked in the exploring file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_student_unimestre_unique = info_student_unimestre.groupby('ds_email').first().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing the join again with the new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_left = rd_station_profile.merge(info_student_unimestre_unique, left_on='email', right_on='ds_email', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_left = merge_left.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new column saying it's a student when a cd_pessoa is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aluno\n",
       "0    37278\n",
       "1     4062\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_left['aluno'] = (merge_left['cd_pessoa'].notnull()).astype(int)\n",
    "merge_left['aluno'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Got different columns with representing the same thing, compiling all in one new columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represents city of the person: 'ds_cidade', 'Cidade Final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_left.loc[:, 'cidade'] = (\n",
    "    merge_left['ds_cidade']\n",
    "    .fillna(merge_left['cidade_final'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Represents city of the person: 'ds_cidade', 'Cidade Final'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_left.loc[:, 'data_nascimento'] = (\n",
    "    merge_left['dt_nascimento']\n",
    "    .fillna(merge_left['data_de_nascimento'])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this I was able to reduce \n",
    "- *Cidade* had 35856 null values now 33986\n",
    "- *Data Nascimento* had 38346 null values now 36117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping columns with replicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_left = merge_left.drop(columns=['ds_cidade', 'cidade_final', 'dt_nascimento', 'data_de_nascimento'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All not null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>lead_scoring_-_perfil</th>\n",
       "      <th>url_pública</th>\n",
       "      <th>estágio_no_funil</th>\n",
       "      <th>total_de_conversões</th>\n",
       "      <th>lead_scoring_-_interesse</th>\n",
       "      <th>status_para_comunicação_por_email</th>\n",
       "      <th>data_da_primeira_conversão</th>\n",
       "      <th>eventos_(últimos_100)</th>\n",
       "      <th>origem_da_última_conversão</th>\n",
       "      <th>...</th>\n",
       "      <th>qual_o_curso_de_interesse?</th>\n",
       "      <th>cargo_final</th>\n",
       "      <th>area_atuacao</th>\n",
       "      <th>interesse_final</th>\n",
       "      <th>ds_email</th>\n",
       "      <th>cd_pessoa</th>\n",
       "      <th>min_dt_log</th>\n",
       "      <th>aluno</th>\n",
       "      <th>cidade</th>\n",
       "      <th>data_nascimento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>carolineklock@hotmail.com</td>\n",
       "      <td>c</td>\n",
       "      <td>http://app.rdstation.com.br/leads/public/8717b...</td>\n",
       "      <td>Lead Qualificado</td>\n",
       "      <td>16</td>\n",
       "      <td>120</td>\n",
       "      <td>True</td>\n",
       "      <td>2015-09-01 19:17:37 -0300</td>\n",
       "      <td>jornada-assessment-instrumentos-para-lideranca...</td>\n",
       "      <td>Busca Orgânica | Bing</td>\n",
       "      <td>...</td>\n",
       "      <td>Educação empresarial / Remuneração</td>\n",
       "      <td>Outros Cargos</td>\n",
       "      <td>RH</td>\n",
       "      <td>formulario-de-pre-inscricao</td>\n",
       "      <td>carolineklock@hotmail.com</td>\n",
       "      <td>128609.0</td>\n",
       "      <td>2018-04-05 19:53:30</td>\n",
       "      <td>1</td>\n",
       "      <td>Joinville</td>\n",
       "      <td>1985-09-21 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15881</th>\n",
       "      <td>stella.bousfield@gmail.com</td>\n",
       "      <td>c</td>\n",
       "      <td>http://app.rdstation.com.br/leads/public/1b271...</td>\n",
       "      <td>Cliente</td>\n",
       "      <td>27</td>\n",
       "      <td>170</td>\n",
       "      <td>True</td>\n",
       "      <td>2015-12-08 10:18:55 -0200</td>\n",
       "      <td>webinar-storytelling / indicado-sarau-de-negoc...</td>\n",
       "      <td>Desconhecido</td>\n",
       "      <td>...</td>\n",
       "      <td>Responsabilidade social</td>\n",
       "      <td>Outros Cargos</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>webinar-storytelling</td>\n",
       "      <td>stella.bousfield@gmail.com</td>\n",
       "      <td>160000017.0</td>\n",
       "      <td>2020-02-27 17:28:20</td>\n",
       "      <td>1</td>\n",
       "      <td>Joinville</td>\n",
       "      <td>1977-06-02 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            email lead_scoring_-_perfil  \\\n",
       "5431    carolineklock@hotmail.com                     c   \n",
       "15881  stella.bousfield@gmail.com                     c   \n",
       "\n",
       "                                             url_pública  estágio_no_funil  \\\n",
       "5431   http://app.rdstation.com.br/leads/public/8717b...  Lead Qualificado   \n",
       "15881  http://app.rdstation.com.br/leads/public/1b271...           Cliente   \n",
       "\n",
       "       total_de_conversões  lead_scoring_-_interesse  \\\n",
       "5431                    16                       120   \n",
       "15881                   27                       170   \n",
       "\n",
       "       status_para_comunicação_por_email data_da_primeira_conversão  \\\n",
       "5431                                True  2015-09-01 19:17:37 -0300   \n",
       "15881                               True  2015-12-08 10:18:55 -0200   \n",
       "\n",
       "                                   eventos_(últimos_100)  \\\n",
       "5431   jornada-assessment-instrumentos-para-lideranca...   \n",
       "15881  webinar-storytelling / indicado-sarau-de-negoc...   \n",
       "\n",
       "      origem_da_última_conversão  ...          qual_o_curso_de_interesse?  \\\n",
       "5431       Busca Orgânica | Bing  ...  Educação empresarial / Remuneração   \n",
       "15881               Desconhecido  ...             Responsabilidade social   \n",
       "\n",
       "         cargo_final area_atuacao              interesse_final  \\\n",
       "5431   Outros Cargos           RH  formulario-de-pre-inscricao   \n",
       "15881  Outros Cargos    Marketing         webinar-storytelling   \n",
       "\n",
       "                         ds_email    cd_pessoa           min_dt_log  aluno  \\\n",
       "5431    carolineklock@hotmail.com     128609.0  2018-04-05 19:53:30      1   \n",
       "15881  stella.bousfield@gmail.com  160000017.0  2020-02-27 17:28:20      1   \n",
       "\n",
       "          cidade      data_nascimento  \n",
       "5431   Joinville  1985-09-21 00:00:00  \n",
       "15881  Joinville  1977-06-02 00:00:00  \n",
       "\n",
       "[2 rows x 35 columns]"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_left[merge_left.notna().all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change dtype for columns that are date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just changing - Work but can't use after to do one - other\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anafl\\AppData\\Local\\Temp\\ipykernel_45952\\3683617211.py:18: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise a warning unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df[date_columns] = df[date_columns].apply(lambda col: pd.to_datetime(col, errors='coerce'))\n",
      "C:\\Users\\anafl\\AppData\\Local\\Temp\\ipykernel_45952\\3683617211.py:18: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise a warning unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df[date_columns] = df[date_columns].apply(lambda col: pd.to_datetime(col, errors='coerce'))\n",
      "C:\\Users\\anafl\\AppData\\Local\\Temp\\ipykernel_45952\\3683617211.py:18: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise a warning unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  df[date_columns] = df[date_columns].apply(lambda col: pd.to_datetime(col, errors='coerce'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "email                                                                        object\n",
       "lead_scoring_-_perfil                                                        object\n",
       "url_pública                                                                  object\n",
       "estágio_no_funil                                                             object\n",
       "total_de_conversões                                                           int64\n",
       "lead_scoring_-_interesse                                                      int64\n",
       "status_para_comunicação_por_email                                              bool\n",
       "data_da_primeira_conversão                                           datetime64[ns]\n",
       "eventos_(últimos_100)                                                        object\n",
       "origem_da_última_conversão                                                   object\n",
       "data_da_última_conversão                                             datetime64[ns]\n",
       "origem_da_primeira_conversão                                                 object\n",
       "empresa                                                                      object\n",
       "tags                                                                         object\n",
       "data_da_última_oportunidade                                          datetime64[ns]\n",
       "estado                                                                       object\n",
       "valor_total_da_oportunidade_no_crm_(última_atualização)                     float64\n",
       "qualificação_da_oportunidade_no_crm_(última_atualização)                    float64\n",
       "etapa_do_funil_de_vendas_no_crm_(última_atualização)                         object\n",
       "nome_do_responsável_pela_oportunidade_no_crm_(última_atualização)            object\n",
       "origem_da_oportunidade_no_crm_(última_atualização)                           object\n",
       "possui_interesse_em_realizar_uma_pós-graduação_ou_mba?                       object\n",
       "desejo_receber_o_sustentare_news                                            float64\n",
       "como_você_conheceu_a_sustentare:                                             object\n",
       "universidade                                                                 object\n",
       "qual_o_curso_de_interesse?                                                   object\n",
       "cargo_final                                                                  object\n",
       "area_atuacao                                                                 object\n",
       "interesse_final                                                              object\n",
       "ds_email                                                                     object\n",
       "cd_pessoa                                                                   float64\n",
       "min_dt_log                                                           datetime64[ns]\n",
       "aluno                                                                         int32\n",
       "cidade                                                                       object\n",
       "data_nascimento                                                      datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_columns_to_datetime(df):\n",
    "    \"\"\"\n",
    "    Convert specified columns in a DataFrame to datetime format.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame\n",
    "        The input DataFrame.\n",
    "    - date_columns: list\n",
    "        List of column names to convert to datetime.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame\n",
    "        The DataFrame with specified columns converted to datetime.\n",
    "    \"\"\"\n",
    "\n",
    "    date_columns = ['data_da_primeira_conversão', 'data_da_última_conversão', 'data_da_última_oportunidade', 'data_nascimento', 'min_dt_log']\n",
    "    \n",
    "    df[date_columns] = df[date_columns].apply(lambda col: pd.to_datetime(col, errors='coerce'))\n",
    "    for i in date_columns:\n",
    "        df[i] = pd.to_datetime(df[i], utc=True).dt.tz_convert(None)\n",
    "    return df\n",
    "\n",
    "merge_left = convert_columns_to_datetime(merge_left)\n",
    "merge_left.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_months_since_conversion(df):\n",
    "    \"\"\"\n",
    "    Calculates the number of months since the first conversion based on the 'aluno' column.\n",
    "    Also drop the rows where 'aluno' = 1 and min_dt_log is null\n",
    "\n",
    "    Parameters:\n",
    "    - The input DataFrame containing the necessary columns.\n",
    "\n",
    "    Returns:\n",
    "    - A new column representing the number of months since the first conversion.\n",
    "    \"\"\"\n",
    "    # Drop rows based on conditions\n",
    "    df = df.drop(df[(df['aluno'] == 1) & df['min_dt_log'].isnull()].index)  # Before have 765 rows that it's student and has the min_dt_log nul\n",
    "    # As it's crucial for the rest of the analysis need to drop these rows \n",
    "\n",
    "    # Calculate months since conversion\n",
    "    df['months_since_conversion'] = np.where(\n",
    "        df['aluno'] == 1,\n",
    "        (df['min_dt_log'] - df['data_da_primeira_conversão']).dt.days / 30,\n",
    "        (datetime.now() - df['data_da_primeira_conversão']).dt.days / 30\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the combined function to your DataFrame\n",
    "merge_left = calculate_months_since_conversion(merge_left)\n",
    "\n",
    "# Verify the changes\n",
    "merge_left.loc[merge_left['aluno'] == 1, 'min_dt_log'].isnull().sum()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironhack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
